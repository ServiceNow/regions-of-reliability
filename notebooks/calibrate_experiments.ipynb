{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e30a493",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2023 ServiceNow\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-suite",
   "metadata": {},
   "source": [
    "The role of this notebook is, for each experiment and each dimensionality tested, the value of the free parameter such that the false negative rate for the negative log-likelihood metric is equal to a specific value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ror.experiments import h0_vs_h1 as exp_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-firmware",
   "metadata": {},
   "source": [
    "We take 3 multivariate gaussian distributions:\n",
    "* Ground-Truth: $y \\sim N(\\eta, \\Lambda)$\n",
    "* First forecast: $x \\sim N(\\mu, \\Sigma)$\n",
    "* Second forecast: $x \\sim N(\\mu', \\Sigma')$\n",
    "\n",
    "The negative log-likelihood for the first forecast is:\n",
    "$$\n",
    "NLL(y) =\n",
    "\\frac{d}{2} \\log{2\\pi}\n",
    "+ \\frac{1}{2} \\log \\det \\Sigma\n",
    "+ \\frac{1}{2} (y-\\mu)^T \\Sigma^{-1} (y-\\mu)\n",
    "$$\n",
    "And the difference between the negative log-likelihood of the first and second forecasts is:\n",
    "$$\n",
    "\\Delta(y) =\n",
    "\\frac{1}{2} (\\log \\det \\Sigma - \\log \\det \\Sigma')\n",
    "+ \\frac{1}{2} (y-\\mu)^T \\Sigma^{-1} (y-\\mu)\n",
    "- \\frac{1}{2} (y-\\mu')^T \\Sigma'^{-1} (y-\\mu')\n",
    "$$\n",
    "\n",
    "The expectation of $\\Delta$ over the Ground-Truth is:\n",
    "$$\n",
    "\\mathbb{E}[\\Delta] =\n",
    "\\frac{1}{2} (\\log \\det \\Sigma - \\log \\det \\Sigma')\n",
    "+ \\frac{1}{2} (\\eta-\\mu)^T \\Sigma^{-1} (\\eta-\\mu)\n",
    "- \\frac{1}{2} (\\eta-\\mu')^T \\Sigma'^{-1} (\\eta-\\mu')\n",
    "+ \\frac{1}{2} \\mathrm{tr} \\Lambda^T \\Sigma^{-1}\n",
    "- \\frac{1}{2} \\mathrm{tr} \\Lambda^T \\Sigma'^{-1}\n",
    "$$\n",
    "\n",
    "The expectation of $\\Delta^2$ over the Ground-Truth is:\n",
    "$$\n",
    "\\mathbb{E}[\\Delta^2] =\n",
    "\\frac{1}{4} K(\\Sigma, \\Sigma')^2\n",
    "+ \\frac{1}{2} K(\\Sigma, \\Sigma') A(\\mu, \\Sigma) - \\frac{1}{2} K(\\Sigma, \\Sigma') A(\\mu', \\Sigma')\n",
    "+ \\frac{1}{4} B(\\mu, \\Sigma, \\mu, \\Sigma) + \\frac{1}{4} B(\\mu', \\Sigma', \\mu', \\Sigma') - \\frac{1}{2} B(\\mu, \\Sigma, \\mu', \\Sigma')\n",
    "$$\n",
    "\n",
    "Where (note that $\\Lambda^T = \\Lambda$, and same for $\\Sigma$ and $\\Sigma'$):\n",
    "\\begin{eqnarray}\n",
    "K(\\Sigma, \\Sigma') & = & \\log \\det \\Sigma - \\log \\det \\Sigma' \\\\\n",
    "A(\\mu, \\Sigma) & = & (\\eta-\\mu)^T \\Sigma^{-1} (\\eta-\\mu) + \\mathrm{tr} \\Lambda^T \\Sigma^{-1} \\\\\n",
    "B(\\mu, \\Sigma, \\mu', \\Sigma') & = & \n",
    "  \\mathrm{tr} \\Lambda^T \\Sigma^{-1} \\cdot \\mathrm{tr} \\Lambda^T \\Sigma'^{-1} \\\\\n",
    "& & + 2 \\cdot \\mathrm{tr} \\Lambda^T (\\Sigma^{-1})^T \\Lambda \\Sigma'^{-1} \\\\\n",
    "& & + \\mathrm{tr} \\Lambda^T \\Sigma^{-1} \\cdot (\\eta-\\mu')^T \\Sigma'^{-1} (\\eta-\\mu') \\\\\n",
    "& & + \\mathrm{tr} \\Lambda^T \\Sigma'^{-1} \\cdot (\\eta-\\mu)^T \\Sigma^{-1} (\\eta-\\mu) \\\\\n",
    "& & + 4 \\cdot (\\eta-\\mu) (\\Sigma^{-1})^T \\Lambda \\Sigma'^{-1} (\\eta-\\mu') \\\\\n",
    "& & + (\\eta-\\mu)^T \\Sigma^{-1} (\\eta-\\mu) \\cdot (\\eta-\\mu')^T \\Sigma'^{-1} (\\eta-\\mu')\n",
    "\\end{eqnarray}\n",
    "\n",
    "And rewritting $\\mathbb{E}[\\Delta]$ using these quantities:\n",
    "$$\n",
    "\\mathbb{E}[\\Delta] = \\frac{1}{2} K(\\Sigma, \\Sigma') + \\frac{1}{2} A(\\mu, \\Sigma) - \\frac{1}{2}A(\\mu', \\Sigma')\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_eq(sigma1, sigma2):\n",
    "    return np.linalg.slogdet(sigma1)[1] - np.linalg.slogdet(sigma2)[1]\n",
    "\n",
    "def a_eq(mean, cov, mu, sigma):\n",
    "    inv_sigma = np.linalg.inv(sigma)\n",
    "    return (mean - mu) @ inv_sigma @ (mean - mu) + np.trace(cov @ inv_sigma)\n",
    "\n",
    "def b_eq(mean, cov, mu1, sigma1, mu2, sigma2):\n",
    "    inv_sigma1 = np.linalg.inv(sigma1)\n",
    "    inv_sigma2 = np.linalg.inv(sigma2)\n",
    "    result = np.trace(cov @ inv_sigma1) * np.trace(cov @ inv_sigma2)\n",
    "    result += 2 * np.trace(cov @ inv_sigma1 @ cov @ inv_sigma2)\n",
    "    result += np.trace(cov @ inv_sigma1) * ((mean - mu2) @ inv_sigma2 @ (mean - mu2))\n",
    "    result += np.trace(cov @ inv_sigma2) * ((mean - mu1) @ inv_sigma1 @ (mean - mu1))\n",
    "    result += 4 * ((mean - mu1) @ inv_sigma1 @ cov @ inv_sigma2 @ (mean - mu2))\n",
    "    result += ((mean - mu1) @ inv_sigma1 @ (mean - mu1)) * ((mean - mu2) @ inv_sigma2 @ (mean - mu2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta = Ground-Truth metric - Forecast metric, so its mean is negative\n",
    "def exp_delta(mean, cov, mu1, sigma1, mu2, sigma2):\n",
    "    return 0.5 * k_eq(sigma1, sigma2) + 0.5 * a_eq(mean, cov, mu1, sigma1) - 0.5 * a_eq(mean, cov, mu2, sigma2)\n",
    "\n",
    "def exp_delta2(mean, cov, mu1, sigma1, mu2, sigma2):\n",
    "    result = 0.25 * k_eq(sigma1, sigma2) * k_eq(sigma1, sigma2)\n",
    "    result += 0.5 * k_eq(sigma1, sigma2) * a_eq(mean, cov, mu1, sigma1)\n",
    "    result += -0.5 * k_eq(sigma1, sigma2) * a_eq(mean, cov, mu2, sigma2)\n",
    "    result += 0.25 * b_eq(mean, cov, mu1, sigma1, mu1, sigma1)\n",
    "    result += 0.25 * b_eq(mean, cov, mu2, sigma2, mu2, sigma2)\n",
    "    result += -0.5 * b_eq(mean, cov, mu1, sigma1, mu2, sigma2)\n",
    "    return result\n",
    "\n",
    "def std_delta(mean, cov, mu1, sigma1, mu2, sigma2):\n",
    "    return (exp_delta2(mean, cov, mu1, sigma1, mu2, sigma2) - exp_delta(mean, cov, mu1, sigma1, mu2, sigma2)**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_for_alpha(d_mean, d_std, num_gt, alpha):   \n",
    "    return num_gt**0.5 * d_std * scipy.stats.norm.ppf(alpha)\n",
    "\n",
    "def get_beta_from_threshold(d_mean, d_std, num_gt, threshold):  \n",
    "    return 1 - scipy.stats.norm.cdf((threshold - num_gt * d_mean) / (num_gt**0.5 * d_std))\n",
    "\n",
    "def beta_diff(param, gen, dim, num_gt, alpha, beta_target):\n",
    "    pair_diff = gen(dim, param)\n",
    "    mu_gt, sigma_gt, mu_fcst, sigma_fcst = pair_diff.get_gaussian_parameters()\n",
    "    d_mean = exp_delta(mu_gt, sigma_gt, mu_gt, sigma_gt, mu_fcst, sigma_fcst)\n",
    "    d_std = std_delta(mu_gt, sigma_gt, mu_gt, sigma_gt, mu_fcst, sigma_fcst)\n",
    "    \n",
    "    t = get_threshold_for_alpha(d_mean, d_std, num_gt, alpha)\n",
    "    beta = get_beta_from_threshold(d_mean, d_std, num_gt, t)\n",
    "    return beta - beta_target\n",
    "\n",
    "def calibrate_gaussian(exp):\n",
    "    gen = exp_def.EXP_GEN[exp]\n",
    "    \n",
    "    return {\n",
    "        dim: scipy.optimize.root_scalar(\n",
    "            beta_diff,\n",
    "            args=(gen, dim, exp_def.NUM_DRAWS, exp_def.ALPHA, exp_def.BETA_NLL),\n",
    "            bracket=exp_def.EXP_PARAMETER_RANGE[exp],\n",
    "            xtol=1e-5,\n",
    "        ).root\n",
    "        for dim in exp_def.DIM_LIST\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-patent",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results_gaussian = {}\n",
    "for exp in exp_def.EXP_LIST:\n",
    "    if exp_def.EXP_GEN[exp] is not None and hasattr(exp_def.EXP_GEN[exp](16, 0), \"get_gaussian_parameters\"):\n",
    "        print(exp, \"calibration:\")\n",
    "        results_gaussian[exp] = calibrate_gaussian(exp)\n",
    "        pprint(results_gaussian[exp], width=1)\n",
    "    else:\n",
    "        print(exp, \"--- Skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b330e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results_gaussian, width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_beta(param, gen, dim, num_gt, alpha, num_samples):\n",
    "    rng = np.random.default_rng(12345)\n",
    "   \n",
    "    pair_diff = gen(dim, param)\n",
    "    dist_gt, dist_fcst = pair_diff.get_distributions()\n",
    "\n",
    "    results = []\n",
    "    for _ in range(num_samples):\n",
    "        targets = dist_gt.sample(1, rng)[0]\n",
    "        nll_gt = -dist_gt.log_pdf(targets)\n",
    "        nll_fcst = -dist_fcst.log_pdf(targets)\n",
    "        results.append(nll_gt - nll_fcst)\n",
    "    results = np.array(results)\n",
    "    d_mean = results.mean()\n",
    "    d_std = results.std()\n",
    "    \n",
    "    t = get_threshold_for_alpha(d_mean, d_std, num_gt, alpha)\n",
    "    return get_beta_from_threshold(d_mean, d_std, num_gt, t)\n",
    "\n",
    "def numerical_beta_diff(param, gen, dim, num_gt, alpha, beta_target, num_samples):\n",
    "    return nll_beta(param, gen, dim, num_gt, alpha, num_samples) - beta_target\n",
    "\n",
    "def calibrate_non_gaussian(exp):\n",
    "    gen = exp_def.EXP_GEN[exp]\n",
    "    \n",
    "    return {\n",
    "        dim: scipy.optimize.root_scalar(\n",
    "            numerical_beta_diff,\n",
    "            args=(gen, dim, exp_def.NUM_DRAWS, exp_def.ALPHA, exp_def.BETA_NLL, 100000),\n",
    "            bracket=exp_def.EXP_PARAMETER_RANGE[exp],\n",
    "            xtol=1e-5,\n",
    "        ).root\n",
    "        for dim in exp_def.DIM_LIST\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_non_gaussian = {}\n",
    "for exp in exp_def.EXP_LIST:\n",
    "    if exp_def.EXP_GEN[exp] is not None and not hasattr(exp_def.EXP_GEN[exp](16, 0), \"get_gaussian_parameters\"):\n",
    "        print(exp, \"calibration:\")\n",
    "        results_non_gaussian[exp] = calibrate_non_gaussian(exp)\n",
    "        pprint(results_non_gaussian[exp], width=1)\n",
    "    else:\n",
    "        print(exp, \"--- Skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results_non_gaussian, width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_def.EXP_LIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

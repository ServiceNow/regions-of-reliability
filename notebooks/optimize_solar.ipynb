{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d040dfe",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2023 ServiceNow\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d6f4c",
   "metadata": {},
   "source": [
    "This notebook optimize a simple Mixed-Integer Programming model with data taken from a probabilistic forecast of the `solar_10min` dataset, to be compared with the same data after errors have been added to the forecast.\n",
    "It then compute the ability of some metrics to detect said errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linprog\n",
    "import sklearn\n",
    "import scipy\n",
    "from ror.experiments import h0_vs_h1 as exp_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_file = \"./data/forecast_solar.npy\"\n",
    "forecast = np.load(forecast_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast = forecast.clip(min=0)\n",
    "# forecast = forecast / forecast.mean(axis=(0,1), keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(samples):\n",
    "    return samples\n",
    "\n",
    "def break_correlations(samples):\n",
    "    return np.random.default_rng().permuted(samples, axis=0)\n",
    "\n",
    "def permute_units(samples):\n",
    "    return np.random.default_rng().permutation(samples, axis=2)\n",
    "\n",
    "def permute_timesteps(samples):\n",
    "    return np.random.default_rng().permutation(samples, axis=1)\n",
    "\n",
    "def multiply_data(factor):\n",
    "    def func(samples):\n",
    "        return samples * factor\n",
    "    return func\n",
    "\n",
    "def increment_data(increment):\n",
    "    def func(samples):\n",
    "        return (samples + increment).clip(min=0)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_linprog(forecast, regret_coef, max_activate, verbose=True):\n",
    "    NUM_SCEN = forecast.shape[0]\n",
    "    NUM_TIME = forecast.shape[1]\n",
    "    NUM_UNIT = forecast.shape[2]\n",
    "    \n",
    "    # Indices of variables:\n",
    "    # * How much of the unit `i` is activate: index = `i`\n",
    "    # * How much power are we selling at time `t`: index = `NUM_UNIT + t`\n",
    "    # * How much power are we missing at time `t` in scenario `v`: index = `NUM_UNIT + NUM_TIME + NUM_SCEN * t + v`\n",
    "    TOTAL_VAR = NUM_UNIT + NUM_TIME + NUM_SCEN * NUM_TIME\n",
    "    \n",
    "    # Objective (minimization):\n",
    "    # Negative sum of sold power for all times `t`;\n",
    "    # plus sum of missing power for all times `t` and scenarios `v`,\n",
    "    # multiplied by a regret aversion coefficient and divided by the number of scenarios.\n",
    "    c = np.zeros(TOTAL_VAR)\n",
    "    c[NUM_UNIT:NUM_UNIT+NUM_TIME] = -1\n",
    "    c[NUM_UNIT+NUM_TIME:] = regret_coef / NUM_SCEN\n",
    "    \n",
    "    # Bounds:\n",
    "    # * Unit activation: `[0,1]`\n",
    "    # * Sold power: `[0,infinity]`\n",
    "    # * Missing power: `[0,infinity]`\n",
    "    bounds = [(0,1) for _ in range(NUM_UNIT)] + \\\n",
    "        [(0,None) for _ in range(NUM_TIME)] + \\\n",
    "        [(0,None) for _ in range(NUM_SCEN * NUM_TIME)]\n",
    "    \n",
    "    # Maximum activate constraint:\n",
    "    # Sum of all unit activation must be below some constant.\n",
    "    A_ub_max_activate = np.zeros((1, TOTAL_VAR))\n",
    "    b_ub_max_activate = np.zeros(1)\n",
    "    A_ub_max_activate[0,0:NUM_UNIT] = 1\n",
    "    b_ub_max_activate[0] = max_activate\n",
    "    \n",
    "    # Underproduction constraints:\n",
    "    # Declared production minus missed production, minus sum of each unit production times its activation,\n",
    "    # must be non-positive.\n",
    "    A_ub_underprod = np.zeros((NUM_SCEN * NUM_TIME, TOTAL_VAR))\n",
    "    b_ub_underprod = np.zeros(NUM_SCEN * NUM_TIME)\n",
    "\n",
    "    for t in range(NUM_TIME):\n",
    "        for v in range(NUM_SCEN):\n",
    "            A_ub_underprod[NUM_SCEN * t + v, NUM_UNIT + t] = 1\n",
    "            A_ub_underprod[NUM_SCEN * t + v, NUM_UNIT + NUM_TIME + NUM_SCEN * t + v] = -1\n",
    "            for i in range(NUM_UNIT):\n",
    "                A_ub_underprod[NUM_SCEN * t + v, i] = -forecast[v, t, i]\n",
    "            b_ub_underprod[NUM_SCEN * t + v] = 0\n",
    "            \n",
    "    A_ub = np.concatenate([A_ub_max_activate, A_ub_underprod], axis=0)\n",
    "    b_ub = np.concatenate([b_ub_max_activate, b_ub_underprod], axis=0)\n",
    "    \n",
    "    result = linprog(\n",
    "        c=c,\n",
    "        A_ub=A_ub,\n",
    "        b_ub=b_ub,\n",
    "        bounds=bounds,\n",
    "        method=\"highs\"\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Objective value:\", -result.fun)\n",
    "    return result.x[0:NUM_UNIT], result.x[NUM_UNIT:NUM_UNIT+NUM_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_objective(forecast, regret_coef, activations, sales):\n",
    "    production = (forecast * activations[None,None,:]).sum(axis=2)\n",
    "    missing_prod = (sales[None,:] - production).clip(min=0)\n",
    "    return (sales - regret_coef * missing_prod).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_foresight_objective(forecast, regret_coef, max_activations):\n",
    "    result = 0    \n",
    "    for scenario in range(forecast.shape[0]):\n",
    "        single_forecast = forecast[scenario:scenario+1,:,:]\n",
    "        act, sl = optimize_linprog(single_forecast, regret_coef, max_activations, verbose=False)\n",
    "        result = result + compute_expected_objective(single_forecast, regret_coef, act, sl).item()\n",
    "    return result / forecast.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_loss_of_profit(forecast_gt, transformation_fcst, regret_coef, max_activations, num_trials=1):\n",
    "    act, sl = optimize_linprog(forecast_gt, regret_coef, max_activations, verbose=False)\n",
    "    values_gt = compute_expected_objective(forecast_gt, regret_coef, act, sl)\n",
    "    \n",
    "    values_fcst = np.zeros(0)\n",
    "    for _ in range(num_trials):\n",
    "        forecast_fcst = transformation_fcst(forecast_gt)\n",
    "        act, sl = optimize_linprog(forecast_fcst, regret_coef, max_activations, verbose=False)\n",
    "        temp = compute_expected_objective(forecast_gt, regret_coef, act, sl)\n",
    "        values_fcst = np.concatenate([values_fcst, temp])\n",
    "    \n",
    "    is_fcst = np.concatenate([np.zeros(len(values_gt)), np.ones(len(values_fcst))])\n",
    "    values = np.concatenate([values_gt, values_fcst])\n",
    "    \n",
    "    perfect_foresight = perfect_foresight_objective(forecast_gt, regret_coef, max_activations)\n",
    "    print(\"Perfect foresight =\", perfect_foresight)\n",
    "    print(\"Mean obj (GT)     =\", values_gt.mean())\n",
    "    print(\"Mean obj (FCST)   =\", values_fcst.mean())\n",
    "    print(\"Normalized (GT)   =\", values_gt.mean() / perfect_foresight)\n",
    "    print(\"Normalized (FCST) =\", values_fcst.mean() / perfect_foresight)\n",
    "    print(\"Loss of profit    =\", 1 - values_fcst.mean() / values_gt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRET_COEF = 10.0\n",
    "MAX_ACTIVATIONS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "measure_loss_of_profit(\n",
    "    forecast,\n",
    "    break_correlations,\n",
    "    REGRET_COEF,\n",
    "    MAX_ACTIVATIONS,\n",
    "    num_trials=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "measure_loss_of_profit(\n",
    "    forecast,\n",
    "    multiply_data(1.05),\n",
    "    REGRET_COEF,\n",
    "    MAX_ACTIVATIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4beb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "measure_loss_of_profit(\n",
    "    forecast,\n",
    "    increment_data(0.05),\n",
    "    REGRET_COEF,\n",
    "    MAX_ACTIVATIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec32d25",
   "metadata": {},
   "source": [
    "# Compare with metrics\n",
    "\n",
    "Only metrics which can be computed from a distribution sample are included here. The negative log-likelihood requires the functional form of the model used to generate said distribution. And while we kept a copy of the code and weights of the model, it did not use a very stable code base due to very strict library dependancies to simply run. So we have omitted them from this release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc322db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTION = [\"crps_quantile\", \"energy_1\", \"variogram_1\"]\n",
    "METRICS = {k: v for k, v in exp_def.METRIC_FUNCTIONS.items() if k in SELECTION}\n",
    "TRANSFORMATIONS = {\n",
    "    \"ground truth\": do_nothing,\n",
    "    \"break correlations\": break_correlations,\n",
    "    \"multiply by 1.05\": multiply_data(1.05),\n",
    "    \"add 0.05\": increment_data(0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_power(gt_score, fcst_score):\n",
    "    diffs = gt_score - fcst_score\n",
    "    d_mean = diffs.mean()\n",
    "    d_std = diffs.std()\n",
    "    \n",
    "    alpha = 0.05\n",
    "    num_draws = 7\n",
    "    threshold = num_draws**0.5 * d_std * scipy.stats.norm.ppf(alpha)\n",
    "    logsf = scipy.stats.norm.logsf((threshold - num_draws * d_mean) / (num_draws**0.5 * d_std))\n",
    "    if (~np.isnan(logsf)):\n",
    "        base10sf = logsf / np.log(10)\n",
    "        exponent = int(np.floor(base10sf))\n",
    "        mantisse = 10 ** (base10sf - exponent)\n",
    "        cdf = scipy.stats.norm.cdf((threshold - num_draws * d_mean) / (num_draws**0.5 * d_std))\n",
    "        return f\"1 - {mantisse} * 10^{exponent} = {cdf}\"\n",
    "    else:\n",
    "        return \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics_df(forecast_gt, transformations, metrics, num_trials=1):\n",
    "    results = []\n",
    "    for metric_name, metric in metrics.items():\n",
    "        for transformation_name, transformation in transformations.items():\n",
    "            for gt_index in range(forecast_gt.shape[0]):\n",
    "                # Remove the ground-truth from the forecast, since this is a pretty huge bias for some metrics\n",
    "                forecast_without_gt = np.concatenate([forecast_gt[:gt_index], forecast_gt[gt_index+1:]])\n",
    "                for trial in range(num_trials):\n",
    "                    forecast_fcst = transformation(forecast_without_gt)\n",
    "                    value = metric(forecast_gt[gt_index], forecast_fcst)\n",
    "                    results.append({\n",
    "                        \"metric\": metric_name,\n",
    "                        \"transformation\": transformation_name,\n",
    "                        \"trial\": trial + 1,\n",
    "                        \"entry\": gt_index + 1,\n",
    "                        \"value\": value,\n",
    "                    })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b492a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_df = all_metrics_df(forecast[:, :, :], TRANSFORMATIONS, METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in METRICS:\n",
    "    for transformation in TRANSFORMATIONS:\n",
    "        if transformation != \"ground truth\":\n",
    "            stat_power = get_stat_power(\n",
    "                full_df[(full_df.transformation == \"ground truth\") & (full_df.metric == metric)].set_index(\"entry\").value,\n",
    "                full_df[(full_df.transformation == transformation) & (full_df.metric == metric)].set_index(\"entry\").value,\n",
    "            )\n",
    "            print(f\"{metric}, {transformation}: Stat Power = {stat_power}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286ba50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
